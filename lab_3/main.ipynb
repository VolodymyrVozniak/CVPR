{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основні функції та змінні"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Імпортуємо необхідні бібліотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Код попередньої лабки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectRecignition:\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        path_main: string -- path for main (train) image\n",
    "        directory_test: string -- directory with all images for testing\n",
    "        directory_save: string -- directory where you want to save all possible savings\n",
    "        n_features: int -- number of features that will be used as a parameter for ORB descriptor (default: 1500)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, path_main, directory_test, directory_save, n_features=1500):\n",
    "        self.path_main = path_main\n",
    "        self.directory_test = directory_test\n",
    "        self.directory_save = directory_save\n",
    "        self.n_features = n_features\n",
    "        self.__orb = cv2.ORB_create(nfeatures=n_features)\n",
    "        self.img_main = cv2.imread(path_main, cv2.IMREAD_GRAYSCALE)\n",
    "        self.keypoints_main, self.descriptors_main = self.__orb.detectAndCompute(self.img_main, None)\n",
    "        self.__bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    \n",
    "    \n",
    "    def get_metrics(self, path):\n",
    "        \"\"\"\n",
    "        Return metrics for main and another image\n",
    "        Arguments:\n",
    "            path: string -- path for another image\n",
    "        Returns:\n",
    "            features: int -- number of features\n",
    "            all_matches: int -- number of all matches\n",
    "            true_matches: int -- number of true matches (find by findHomography)\n",
    "            error_all_matches: float -- mean of distances of DMatch objects for all matches\n",
    "            error_true_matches: float -- mean of distances of DMatch objects for true matches\n",
    "            size: tuple -- size of image\n",
    "            time: float -- time of running the function\n",
    "        \"\"\"        \n",
    "        # Initialize an image\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        kp, des = self.__orb.detectAndCompute(img, None)\n",
    "        \n",
    "        # Find features\n",
    "        features = self.n_features\n",
    "        \n",
    "        # Find time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Find all_matches\n",
    "        try:\n",
    "            matches = self.__bf.match(self.descriptors_main, des)\n",
    "        except:\n",
    "            print(\"Something wrong with image\", path)\n",
    "            return np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "        matches = sorted(matches, key = lambda x: x.distance)\n",
    "        all_matches = len(matches)\n",
    "        \n",
    "        # Find true_matches\n",
    "        query_pts = np.float32([self.keypoints_main[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        train_pts = np.float32([kp[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        _, mask = cv2.findHomography(query_pts, train_pts, cv2.RANSAC, 5.0)\n",
    "        matches_mask = mask.ravel().tolist()\n",
    "        true_matches_list = []\n",
    "        for index, el in enumerate(matches_mask):\n",
    "            if el == 1:\n",
    "                true_matches_list.append(matches[index])\n",
    "        true_matches = len(true_matches_list)\n",
    "        \n",
    "        # Find time\n",
    "        end_time = time.time()\n",
    "        time_ = round(end_time - start_time, 4)\n",
    "        \n",
    "        # Find error_all_matches\n",
    "        if all_matches == 0:\n",
    "            error_all_matches = np.nan\n",
    "        else:\n",
    "            error_all_matches_list = []\n",
    "            for m in matches:\n",
    "                error_all_matches_list.append(m.distance)\n",
    "            error_all_matches = round(np.array(error_all_matches_list).mean(), 4)\n",
    "        \n",
    "        # Find error_true_matches\n",
    "        if true_matches == 0:\n",
    "            error_true_matches = np.nan\n",
    "        else:\n",
    "            error_true_matches_list = []\n",
    "            for m in true_matches_list:\n",
    "                error_true_matches_list.append(m.distance)\n",
    "            error_true_matches = round(np.array(error_true_matches_list).mean(), 4)\n",
    "        \n",
    "        # Find size\n",
    "        size = img.shape\n",
    "        \n",
    "        # Здається, що алгоримт завжди знаходить у районі 10 true_matches, тому будемо вважати 10 еквівалентно 0\n",
    "#         if true_matches < 10:\n",
    "#             true_matches = 0\n",
    "#             error_true_matches = np.nan\n",
    "        \n",
    "        # Return values as tuple\n",
    "        return features, all_matches, true_matches, error_all_matches, error_true_matches, size, time_\n",
    "    \n",
    "        \n",
    "    def get_all_metrics_as_df(self, print_results=False):\n",
    "        \"\"\"\n",
    "        Return all metrics for all images from directory_test as pandas DataFrame\n",
    "        Returns:\n",
    "            df: pandas DataFrame -- a dataframe with all metrics for all images\n",
    "        \"\"\"\n",
    "        all_metrics = []\n",
    "        \n",
    "        for filename in os.listdir(self.directory_test):\n",
    "            path = self.directory_test + '\\\\\\\\' + filename\n",
    "            temp_list = list(self.get_metrics(path))\n",
    "            temp_list.insert(0, filename)\n",
    "            all_metrics.append(temp_list)\n",
    "            \n",
    "        df = pd.DataFrame(all_metrics, columns=['name', 'features', 'all_matches', 'true_matches', \n",
    "                                                'error_all_matches', 'error_true_matches', 'size', 'time'])\n",
    "        return df\n",
    "        \n",
    "    \n",
    "    def save_all_metrics(self, file_name):\n",
    "        \"\"\"\n",
    "        Save all metrics for all images as csv file\n",
    "        Arguments:\n",
    "            file_name: string -- name of the file (without the format)\n",
    "        \"\"\"\n",
    "        df = self.get_all_metrics_as_df()\n",
    "        df.to_csv(self.directory_save + '\\\\\\\\' + file_name + '.csv') \n",
    "    \n",
    "    \n",
    "    def show_features(self, save=False):\n",
    "        \"\"\"\n",
    "        Show features on the main image\n",
    "        Arguments:\n",
    "            save: bool -- save received image or not (default: False)\n",
    "        \"\"\"\n",
    "        img_keys = cv2.drawKeypoints(self.img_main, self.keypoints_main, None)\n",
    "        cv2.namedWindow(\"Image\", cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow(\"Image\", 600, 600)\n",
    "        cv2.imshow(\"Image\", img_keys)\n",
    "        \n",
    "        if save:\n",
    "            file_name = self.directory_save + '\\\\\\\\' + 'features_for_' + self.path_main.split('\\\\')[-1]\n",
    "            cv2.imwrite(file_name, img_keys)\n",
    "        \n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "    def show_all_matches(self, random=True, path='', save=False):\n",
    "        \"\"\"\n",
    "        Show all matches between main and another image\n",
    "        Arguments:\n",
    "            random: bool -- show all matches for random image if random set to True (default: True)\n",
    "            path: string -- path for another image if random set to False (default: empty string)\n",
    "            save: bool -- save received image or not (default: False)\n",
    "        \"\"\"\n",
    "        if random:\n",
    "            path = self.directory_test + '\\\\\\\\' + np.random.choice(os.listdir(self.directory_test))\n",
    "        else:\n",
    "            if path == '':\n",
    "                return \"Please enter the path or set random to True\"\n",
    "            \n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        kp, des = self.__orb.detectAndCompute(img, None)\n",
    "        \n",
    "        matches = self.__bf.match(self.descriptors_main, des)\n",
    "        matches = sorted(matches, key = lambda x: x.distance)\n",
    "        \n",
    "        matching_result = cv2.drawMatches(self.img_main, self.keypoints_main, img, kp, matches, None)\n",
    "        \n",
    "        cv2.namedWindow(\"Matches\", cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow(\"Matches\", 1200, 600)\n",
    "        cv2.imshow(\"Matches\", matching_result)\n",
    "        \n",
    "        if save:\n",
    "            file_name = self.directory_save + '\\\\\\\\' +  'all_matches_for_' + path.split('\\\\')[-1]\n",
    "            cv2.imwrite(file_name, matching_result)\n",
    "        \n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    \n",
    "    def show_true_matches(self, random=True, path='', save=False):\n",
    "        \"\"\"\n",
    "        Show true matches between main and another image (finding by findHomography)\n",
    "        Arguments:\n",
    "            random: bool -- show all matches for random image if random set to True (default: True)\n",
    "            path: string -- path for another image if random set to False (default: empty string)\n",
    "            save: bool -- save received image or not (default: False)\n",
    "        \"\"\"\n",
    "        if random:\n",
    "            path = self.directory_test + '\\\\\\\\' + np.random.choice(os.listdir(self.directory_test))\n",
    "        else:\n",
    "            if path == '':\n",
    "                return \"Please enter the path or set random to True\"\n",
    "            \n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        kp, des = self.__orb.detectAndCompute(img, None)\n",
    "        \n",
    "        matches = self.__bf.match(self.descriptors_main, des)\n",
    "        matches = sorted(matches, key = lambda x: x.distance)\n",
    "        \n",
    "        matching_result = cv2.drawMatches(self.img_main, self.keypoints_main, img, kp, matches, None)\n",
    "        \n",
    "        query_pts = np.float32([self.keypoints_main[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        train_pts = np.float32([kp[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        _, mask = cv2.findHomography(query_pts, train_pts, cv2.RANSAC, 5.0)\n",
    "        matches_mask = mask.ravel().tolist()\n",
    "        \n",
    "        true_matches = []\n",
    "        for index, el in enumerate(matches_mask):\n",
    "            if el == 1:\n",
    "                true_matches.append(matches[index])\n",
    "                \n",
    "        matching_true_relults = cv2.drawMatches(self.img_main, self.keypoints_main, img, kp, true_matches, None)\n",
    "        \n",
    "        cv2.namedWindow(\"True Matches\", cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow(\"True Matches\", 1200, 600)\n",
    "        cv2.imshow(\"True Matches\", matching_true_relults)\n",
    "        \n",
    "        if save:\n",
    "            file_name = self.directory_save + '\\\\\\\\' + 'true_matches_for_' + path.split('\\\\')[-1]\n",
    "            cv2.imwrite(file_name, matching_true_relults)\n",
    "        \n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оголошуємо необхідні змінні"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 500\n",
    "directory_test = \"Library\"\n",
    "include_other_photos = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функція для створення X та y для майбутніх класифікаторів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_and_y(n_features, directory_test, include_other_photos):\n",
    "    \"\"\"\n",
    "    Create X and y for future classifier\n",
    "    Arguments:\n",
    "        n_features: int -- number of features (will be used for defining ORB descriptor)\n",
    "        directory_test: str -- directory with all images for testing\n",
    "        include_other_photos: bool -- spicifies which classifier will be later (binary classifier with only two possible objects\n",
    "                              on photo or ternary classifier with two possible objects on photo and some another type of photos)\n",
    "    Returns:\n",
    "    X: np.array -- matrix X for future classifier\n",
    "    y: np.array -- vector y for future classifier\n",
    "    \"\"\"\n",
    "    X_dict = {}\n",
    "    X = []\n",
    "    y = []\n",
    "    orb = cv2.ORB_create(nfeatures=n_features)\n",
    "    \n",
    "    for filename in os.listdir(directory_test):\n",
    "        path = directory_test + '\\\\\\\\' + filename\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        kp, des = orb.detectAndCompute(img, None)\n",
    "        try:\n",
    "            size = des.shape[0]\n",
    "        except:\n",
    "            print(filename, \"hasn't got any features!\")\n",
    "            continue\n",
    "        if size == 500:\n",
    "            id = int(filename.split('.')[0])\n",
    "            if include_other_photos:\n",
    "                X.append(des)\n",
    "                X_dict[id] = des\n",
    "                if id < 120:\n",
    "                    y.append(2)\n",
    "                elif id > 225:\n",
    "                    y.append(0)\n",
    "                else:\n",
    "                    y.append(1)\n",
    "            else:\n",
    "                if id < 120:\n",
    "                    X.append(des)\n",
    "                    X_dict[id] = des\n",
    "                    y.append(2)\n",
    "                elif id > 225:\n",
    "                    pass\n",
    "                else:\n",
    "                    X.append(des)\n",
    "                    X_dict[id] = des\n",
    "                    y.append(1)\n",
    "        else:\n",
    "            print(filename, \"has less than 500 features!\")\n",
    "                    \n",
    "    X = np.asarray(X)\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    return X, y, X_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Допоміжна функція для наочної перевірки правильності роботи класифікатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_photo(y_test, y_pred, X_test, X_dict):\n",
    "    if y_test == 0:\n",
    "        print(\"This is neither car nor ship!\")\n",
    "    elif y_test == 1:\n",
    "        print(\"This is car!\")\n",
    "    else:\n",
    "        print(\"This is ship!\")\n",
    "    if y_pred == 0:\n",
    "        print(\"My classifier thinks this is neither car nor ship!\")\n",
    "    elif y_pred == 1:\n",
    "        print(\"My classifier thinks this is car!\")\n",
    "    else:\n",
    "        print(\"My classifier thinks this is ship!\")\n",
    "    X_test = X_test.reshape(500, 32)\n",
    "    id = [id for id, el in X_dict.items() if (el == X_test).all()][0]\n",
    "    path = directory_test + '\\\\\\\\' + str(id) + '.jpg'\n",
    "    img = cv2.imread(path, 0)\n",
    "    cv2.namedWindow(\"Image\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"Image\", 600, 600)\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Будуємо тернарний класифікатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.jpg has less than 500 features!\n",
      "171.jpg has less than 500 features!\n",
      "172.jpg has less than 500 features!\n",
      "174.jpg has less than 500 features!\n",
      "175.jpg has less than 500 features!\n",
      "176.jpg has less than 500 features!\n",
      "178.jpg has less than 500 features!\n",
      "202.jpg has less than 500 features!\n",
      "203.jpg has less than 500 features!\n",
      "204.jpg has less than 500 features!\n",
      "225.jpg has less than 500 features!\n",
      "236.jpg has less than 500 features!\n",
      "239.jpg has less than 500 features!\n",
      "240.jpg has less than 500 features!\n",
      "241.jpg hasn't got any features!\n",
      "246.jpg has less than 500 features!\n",
      "255.jpg has less than 500 features!\n",
      "258.jpg has less than 500 features!\n",
      "259.jpg has less than 500 features!\n",
      "263.jpg has less than 500 features!\n",
      "264.jpg has less than 500 features!\n",
      "265.jpg has less than 500 features!\n",
      "267.jpg hasn't got any features!\n",
      "268.jpg has less than 500 features!\n",
      "269.jpg hasn't got any features!\n",
      "30.jpg has less than 500 features!\n",
      "34.jpg has less than 500 features!\n",
      "35.jpg has less than 500 features!\n",
      "36.jpg has less than 500 features!\n",
      "38.jpg has less than 500 features!\n",
      "39.jpg hasn't got any features!\n",
      "46.jpg hasn't got any features!\n",
      "47.jpg has less than 500 features!\n",
      "58.jpg has less than 500 features!\n",
      "59.jpg has less than 500 features!\n",
      "72.jpg has less than 500 features!\n",
      "82.jpg has less than 500 features!\n",
      "83.jpg has less than 500 features!\n",
      "84.jpg has less than 500 features!\n",
      "85.jpg has less than 500 features!\n",
      "86.jpg has less than 500 features!\n",
      "87.jpg has less than 500 features!\n",
      "88.jpg has less than 500 features!\n",
      "91.jpg hasn't got any features!\n",
      "92.jpg hasn't got any features!\n",
      "93.jpg hasn't got any features!\n",
      "94.jpg has less than 500 features!\n",
      "95.jpg has less than 500 features!\n",
      "\n",
      "X shape: (221, 16000)\n",
      "y shape: (221,)\n"
     ]
    }
   ],
   "source": [
    "X, y, X_dict = create_X_and_y(n_features, directory_test, include_other_photos)\n",
    "\n",
    "print()\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Розділяємо вибірку на train та test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (165, 16000)\n",
      "y_train shape: (165,)\n",
      "X_test shape: (56, 16000)\n",
      "y_test shape: (56,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=100)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Використовуємо Logistic Regression як наш класифікатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Виводимо точність для одного із train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Демонструємо наглядну роботу класифікатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1,\n",
       "       2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 2, 0, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 0, 2, 1, 1, 1, 2, 1,\n",
       "       2, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 0, 2, 1, 2, 2, 2, 1, 2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Як ми бачимо, точність класифіктора для даного train_test_split майже 80%, що впринципі досить непогано для такої трейнової вибірки. Вище я вивів очікувані значення y та передбачені. За допомогою функції print_photo можемо повиводити зображення, які наш класифікатор передбачає не вірно.\n",
    "\n",
    "<img src=\"Library\\146.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is car!\n",
      "My classifier thinks this is ship!\n",
      "Library\\\\146.jpg\n"
     ]
    }
   ],
   "source": [
    "print_photo(y_test[2], y_pred[2], X_test[2], X_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Library\\179.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is car!\n",
      "My classifier thinks this is ship!\n",
      "Library\\\\179.jpg\n"
     ]
    }
   ],
   "source": [
    "print_photo(y_test[5], y_pred[5], X_test[5], X_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Library\\238.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is neither car nor ship!\n",
      "My classifier thinks this is ship!\n",
      "Library\\\\238.jpg\n"
     ]
    }
   ],
   "source": [
    "print_photo(y_test[1], y_pred[1], X_test[1], X_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Library\\101.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is ship!\n",
      "My classifier thinks this is car!\n",
      "Library\\\\101.jpg\n"
     ]
    }
   ],
   "source": [
    "print_photo(y_test[-1], y_pred[-1], X_test[-1], X_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так, за цими прикладами здається дуже дивним, що класифікатор не вірно розпізнає об'єкти на цих зображеннях, проте самі зображення дійсно дуже різні (на одному із них лише трішки видніється машинка, головний ракурс на замку, а останнє фото кораблика взагалі трішки розмите, а, як ми уже знаємо із попередньої лабки, ORB є дуже чутливим до освітлення й розмитості фото), а тому однозначного висновку щодо того чому так відбувається зробити не можна. На мою думку, це відбувається через замалу трейн вибірку (лише 165 об'єктів). Та навіть попри таку невеличку вибірку класифікатор працює із точністю близько 70% (для різних train_test_split різна точність), що досить круто. Одне можна сказати напевне: наша вибірка містить замалу кількість фото без машинки й корабля, саме через це вона взагалі не виводить жодного спрогнозованого 0 (що відповідає зображенню без машинки й корабля). Проте було вирішено не міняти початково створену вибірку, оскільки в Андрія, мого колеги по команді (Увага! Спойлер!), навіть на такій виборці з допомогою його дескриптора класифікатор досить адекватно прогнозує 0, для мого ж класифікатора із моїм дескриптором вибірка все ж містить замало фото без машинки й без корабля. Тому наступним кроком спробуємо розглянути бінарну класифікацію на вибірці, яка міститиме лише фото або машинки, або корабля."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Виводимо confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  4]\n",
      " [ 0 19  5]\n",
      " [ 0  2 25]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Це я вивів confusion matrix, із якої досить добре видно кількість правильно спрогнозованих фото та помилки першого й другого роду. Наприклад, класифікатор правильно знаходить 19 машин на фото та 25 кораблів, проте замість того, щоб не знайти нічого, він 4 рази знаходить кораблі й 1 раз машинку, а замість того, щоб знайти машинку, він 5 разів знаходить корабель і тд."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Виводимо точність по cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7432806324110672\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "kf = KFold(shuffle=True, n_splits=10)\n",
    "print(cross_val_score(logreg, X, y, cv=kf, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P.S. У майбутньому користуватимемось цією метрикою, як основною при порівнянні класифікаторів"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Будуємо бінарний класифіктор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.jpg has less than 500 features!\n",
      "171.jpg has less than 500 features!\n",
      "172.jpg has less than 500 features!\n",
      "174.jpg has less than 500 features!\n",
      "175.jpg has less than 500 features!\n",
      "176.jpg has less than 500 features!\n",
      "178.jpg has less than 500 features!\n",
      "202.jpg has less than 500 features!\n",
      "203.jpg has less than 500 features!\n",
      "204.jpg has less than 500 features!\n",
      "225.jpg has less than 500 features!\n",
      "236.jpg has less than 500 features!\n",
      "239.jpg has less than 500 features!\n",
      "240.jpg has less than 500 features!\n",
      "241.jpg hasn't got any features!\n",
      "246.jpg has less than 500 features!\n",
      "255.jpg has less than 500 features!\n",
      "258.jpg has less than 500 features!\n",
      "259.jpg has less than 500 features!\n",
      "263.jpg has less than 500 features!\n",
      "264.jpg has less than 500 features!\n",
      "265.jpg has less than 500 features!\n",
      "267.jpg hasn't got any features!\n",
      "268.jpg has less than 500 features!\n",
      "269.jpg hasn't got any features!\n",
      "30.jpg has less than 500 features!\n",
      "34.jpg has less than 500 features!\n",
      "35.jpg has less than 500 features!\n",
      "36.jpg has less than 500 features!\n",
      "38.jpg has less than 500 features!\n",
      "39.jpg hasn't got any features!\n",
      "46.jpg hasn't got any features!\n",
      "47.jpg has less than 500 features!\n",
      "58.jpg has less than 500 features!\n",
      "59.jpg has less than 500 features!\n",
      "72.jpg has less than 500 features!\n",
      "82.jpg has less than 500 features!\n",
      "83.jpg has less than 500 features!\n",
      "84.jpg has less than 500 features!\n",
      "85.jpg has less than 500 features!\n",
      "86.jpg has less than 500 features!\n",
      "87.jpg has less than 500 features!\n",
      "88.jpg has less than 500 features!\n",
      "91.jpg hasn't got any features!\n",
      "92.jpg hasn't got any features!\n",
      "93.jpg hasn't got any features!\n",
      "94.jpg has less than 500 features!\n",
      "95.jpg has less than 500 features!\n",
      "\n",
      "X shape: (191, 16000)\n",
      "y shape: (191,)\n"
     ]
    }
   ],
   "source": [
    "X, y, X_dict = create_X_and_y(n_features, directory_test, include_other_photos=False)\n",
    "\n",
    "print()\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Розділяємо вибірку на train та test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (143, 16000)\n",
      "y_train shape: (143,)\n",
      "X_test shape: (48, 16000)\n",
      "y_test shape: (48,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=8)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Використовуємо Logistic Regression як наш класифікатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Виводимо точність для одного із train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8958333333333334\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Виводимо confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  2]\n",
      " [ 3 21]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Виводимо точність по cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.807280701754386\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(logreg, X, y, cv=kf, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Останню точність ми й вважаємо нашою основною метрикою при порівнянні класифікаторів, тому ми бачимо, що вона зросла на 10% у порівнянні із попереднім тернарним класифікатором, тобто в 4 із 5 випадків класифікатор правильно знаходить чи машинка на зображенні, чи корабель, що я вважаю мега-круто, як для такої невеличкої трейн вибірки (лише 143 об'єкти)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Розглядаємо інші класифікатори"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Розглянемо ще кілька класифікаторів і подивимося, яку точінсть видають вони для тернарного класифікатору (випадок, коли в трейн вибірці є зображення або із машинкою, або із кораблем, або без нічого). Як і раніше, вважатимемо за основну метрику середній результат точності cross validation (уже знаємо, що для логістичної цей показник становить близько 70%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.jpg has less than 500 features!\n",
      "171.jpg has less than 500 features!\n",
      "172.jpg has less than 500 features!\n",
      "174.jpg has less than 500 features!\n",
      "175.jpg has less than 500 features!\n",
      "176.jpg has less than 500 features!\n",
      "178.jpg has less than 500 features!\n",
      "202.jpg has less than 500 features!\n",
      "203.jpg has less than 500 features!\n",
      "204.jpg has less than 500 features!\n",
      "225.jpg has less than 500 features!\n",
      "236.jpg has less than 500 features!\n",
      "239.jpg has less than 500 features!\n",
      "240.jpg has less than 500 features!\n",
      "241.jpg hasn't got any features!\n",
      "246.jpg has less than 500 features!\n",
      "255.jpg has less than 500 features!\n",
      "258.jpg has less than 500 features!\n",
      "259.jpg has less than 500 features!\n",
      "263.jpg has less than 500 features!\n",
      "264.jpg has less than 500 features!\n",
      "265.jpg has less than 500 features!\n",
      "267.jpg hasn't got any features!\n",
      "268.jpg has less than 500 features!\n",
      "269.jpg hasn't got any features!\n",
      "30.jpg has less than 500 features!\n",
      "34.jpg has less than 500 features!\n",
      "35.jpg has less than 500 features!\n",
      "36.jpg has less than 500 features!\n",
      "38.jpg has less than 500 features!\n",
      "39.jpg hasn't got any features!\n",
      "46.jpg hasn't got any features!\n",
      "47.jpg has less than 500 features!\n",
      "58.jpg has less than 500 features!\n",
      "59.jpg has less than 500 features!\n",
      "72.jpg has less than 500 features!\n",
      "82.jpg has less than 500 features!\n",
      "83.jpg has less than 500 features!\n",
      "84.jpg has less than 500 features!\n",
      "85.jpg has less than 500 features!\n",
      "86.jpg has less than 500 features!\n",
      "87.jpg has less than 500 features!\n",
      "88.jpg has less than 500 features!\n",
      "91.jpg hasn't got any features!\n",
      "92.jpg hasn't got any features!\n",
      "93.jpg hasn't got any features!\n",
      "94.jpg has less than 500 features!\n",
      "95.jpg has less than 500 features!\n",
      "\n",
      "X shape: (221, 16000)\n",
      "y shape: (221,)\n"
     ]
    }
   ],
   "source": [
    "X, y, X_dict = create_X_and_y(n_features, directory_test, include_other_photos=True)\n",
    "\n",
    "print()\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Використовуємо SVM with linear kernel як наш класифікатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7100790513833992\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear')\n",
    "print(cross_val_score(svm, X, y, cv=kf, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Використовуємо SVM with polynomial kernel як наш класифікатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7108319217014868\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm = SVC(kernel='poly', gamma='scale')\n",
    "print(cross_val_score(svm, X, y, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Використовуємо PCA\n",
    "\n",
    "До цього моменту ми розглядали класифікатори, які ідеально підходять для випадку, коли кількість фіч набагато більша за кількість трейн екзамплів (у нас 16000 проти 165). Зараз же зменшимо розмірність нашої матриці X із [221x16000] до [221x100] за допомогою Principal Component Analysis (PCA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Використовуємо SVM with Gaussian kernel with PCA як наш класифікатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7193675889328064\n",
      "Wall time: 99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm = SVC(kernel='rbf', gamma='scale')\n",
    "print(cross_val_score(svm, X_pca, y, cv=kf, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Використовуємо Random Forest with PCA як наш класифікатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7108695652173912\n",
      "Wall time: 2.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=200)\n",
    "print(cross_val_score(rfc, X_pca, y, cv=kf, scoring='accuracy').mean())\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# param_grid = dict(n_estimators=[100, 200, 300, 400, 500, 600, 700, 800, 900, 1000])\n",
    "# grid = GridSearchCV(rfc, param_grid, cv=10, scoring='accuracy', return_train_score=False)\n",
    "# grid.fit(X_pca, y)\n",
    "# print(grid.best_score_)\n",
    "# print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Використовуємо Decision Trees with PCA як наш класифікатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6563241106719369\n",
      "Wall time: 119 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "print(cross_val_score(dtc, X_pca, y, cv=kf, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Використовуємо NN with special PCA як наш класифікатор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я спробував заранити нейронку із sklearn аналогічно до попередніх класифікаторів на матриці розмірності [221x100], проте получив не дужеее поганий результат, близько 45% по cross_validation і вона чомусь завжди прогнозувала тільки 1, або тільки 2, що взагалі не вірно. Тому я вирішив скористатися методом Андрія, який для кожного набору дескрипторів використовував PCA із n_components = 1 і робив із матриці розмірності [2222x64] матрицю розмірності [1x64]. Я спробував піти аналогічним шляхом (весь коди трішки нижче) і в такому разі точність нейронки склала приблизно 64% по cross_validation, що впринципі краще, проте далеко від ідеалу (та ж Логістична й SVM без зтискання даних давали більше 70%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_and_y_pca(n_features, directory_test):\n",
    "    X = []\n",
    "    y = []\n",
    "    orb = cv2.ORB_create(nfeatures=n_features)\n",
    "    pca = PCA(n_components=1)\n",
    "    \n",
    "    for filename in os.listdir(directory_test):\n",
    "        path = directory_test + '\\\\\\\\' + filename\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        kp, des = orb.detectAndCompute(img, None)\n",
    "        id = int(filename.split('.')[0])\n",
    "        try:\n",
    "            size = des.shape[0]\n",
    "        except:\n",
    "            print(filename, \"hasn't got any features!\")\n",
    "            continue\n",
    "        X_pca = pca.fit_transform(des.T)  # .reshape(1,-1)\n",
    "        X.append(X_pca)\n",
    "        # print(id, \"has been processed!\")\n",
    "        if id < 120:\n",
    "            y.append(2)\n",
    "        elif id > 225:\n",
    "            y.append(0)\n",
    "        else:\n",
    "            y.append(1)\n",
    "            \n",
    "    X = np.asarray(X)\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    y = np.asarray(y)\n",
    "                \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241.jpg hasn't got any features!\n",
      "267.jpg hasn't got any features!\n",
      "269.jpg hasn't got any features!\n",
      "39.jpg hasn't got any features!\n",
      "46.jpg hasn't got any features!\n",
      "91.jpg hasn't got any features!\n",
      "92.jpg hasn't got any features!\n",
      "93.jpg hasn't got any features!\n",
      "\n",
      "X shape: (261, 32)\n",
      "y shape: (261,)\n"
     ]
    }
   ],
   "source": [
    "X_for_nn, y_for_nn = create_X_and_y_pca(n_features, directory_test)\n",
    "\n",
    "print()\n",
    "print(\"X shape:\", X_for_nn.shape)\n",
    "print(\"y shape:\", y_for_nn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6509971509971509\n",
      "Wall time: 2.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn = MLPClassifier(hidden_layer_sizes=(200,))\n",
    "kf = KFold(shuffle=True, n_splits=10)\n",
    "print(cross_val_score(nn, X_for_nn, y_for_nn, cv=kf, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Приступаємо до роботи із відео"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Розбиваємо відео на кадри"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidcap = cv2.VideoCapture('video.mp4')\n",
    "success, image = vidcap.read()\n",
    "count = 0\n",
    "while success:\n",
    "    new_count = 1000 + count\n",
    "    cv2.imwrite(\"video_frames/%d.jpg\" % new_count, image)     # save frame as JPEG file      \n",
    "    success, image = vidcap.read()\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функції для створення різних X_test для різних класифікаторів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_for_lr(n_features, directory_test):\n",
    "    X = []\n",
    "    ids = []\n",
    "    ids_for_zero = []\n",
    "    orb = cv2.ORB_create(nfeatures=n_features)\n",
    "    \n",
    "    for index, filename in enumerate(os.listdir(directory_test)):\n",
    "        path = directory_test + '\\\\\\\\' + filename\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        kp, des = orb.detectAndCompute(img, None)\n",
    "        try:\n",
    "            size = des.shape[0]\n",
    "        except:\n",
    "            ids_for_zero.append(index)\n",
    "            print(index, \":\", filename, \"hasn't got any features!\")\n",
    "            continue\n",
    "        if size == 500:\n",
    "            ids.append(index)\n",
    "            X.append(des)\n",
    "        else:\n",
    "            ids_for_zero.append(index)\n",
    "            print(index, \":\", filename, \"has less than 500 features!\")\n",
    "                    \n",
    "    X = np.asarray(X)\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    \n",
    "    return X, ids, ids_for_zero\n",
    "\n",
    "def create_X_for_nn(n_features, directory_test):\n",
    "    X = []\n",
    "    ids = []\n",
    "    ids_for_zero = []\n",
    "    orb = cv2.ORB_create(nfeatures=n_features)\n",
    "    pca = PCA(n_components=1)\n",
    "    \n",
    "    for index, filename in enumerate(os.listdir(directory_test)):\n",
    "        path = directory_test + '\\\\\\\\' + filename\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        kp, des = orb.detectAndCompute(img, None)\n",
    "        try:\n",
    "            size = des.shape[0]\n",
    "        except:\n",
    "            ids_for_zero.append(index)\n",
    "            print(index, \":\", filename, \"hasn't got any features!\")\n",
    "            continue\n",
    "        X_pca = pca.fit_transform(des.T)\n",
    "        ids.append(index)\n",
    "        X.append(X_pca)\n",
    "            \n",
    "    X = np.asarray(X)\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "                \n",
    "    return X, ids, ids_for_zero\n",
    "\n",
    "def add_zeros(y_pred, ids, ids_for_zero):\n",
    "    size = len(ids) + len(ids_for_zero)\n",
    "    y_pred_with_zeros = np.zeros((size), dtype=int)\n",
    "    for i in range(len(ids)):\n",
    "        y_pred_with_zeros[ids[i]] = y_pred[i]\n",
    "    return y_pred_with_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функція для збереження відео із текстовим оверлеєм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_video(y_pred, classifier):\n",
    "    from PIL import Image, ImageDraw, ImageFont\n",
    "    i = 0\n",
    "    \n",
    "    for filename in glob.glob('video_frames/*.jpg'):\n",
    "\n",
    "        #Create an Image Object from an Image\n",
    "        im = Image.open(filename)\n",
    "        photo_index = filename.split('\\\\')[1].split('.')[0]\n",
    "        width, height = im.size\n",
    "        draw = ImageDraw.Draw(im)\n",
    "\n",
    "        if y_pred[i] == 0:\n",
    "            text = \"other object\"\n",
    "        if y_pred[i] == 1:\n",
    "            text = \"car\"\n",
    "        if y_pred[i] == 2:\n",
    "            text = \"ship\"\n",
    "\n",
    "        font = ImageFont.truetype('arial.ttf', 36)\n",
    "        textwidth, textheight = draw.textsize(text, font)\n",
    "\n",
    "        # calculate the x,y coordinates of the text\n",
    "        margin = 10\n",
    "        x = width - textwidth - margin\n",
    "        y = height - textheight - margin\n",
    "\n",
    "        # draw watermark in the bottom right corner\n",
    "        draw.text((x, y), text, font=font)\n",
    "\n",
    "        #Save watermarked image\n",
    "        im.save('Storage/' + classifier + '/' + photo_index + '.jpg')\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    img_array = [0 for i in range(len(glob.glob('Storage/' + classifier + '/' + '*.jpg')))]\n",
    "    i = 0 \n",
    "\n",
    "    for filename in glob.glob('Storage/' + classifier + '/' + '*.jpg'):\n",
    "        img = cv2.imread(filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width, height)\n",
    "        ind = int(filename.split('\\\\')[1].split('.')[0]) - 1000\n",
    "        img_array[ind] = img\n",
    "        i += 1\n",
    "\n",
    "    out = cv2.VideoWriter('result_for_' + classifier + '.mp4', cv2.VideoWriter_fourcc(*'DIVX'), 30, size)\n",
    "\n",
    "    for i in range(len(img_array)):\n",
    "        out.write(img_array[i])\n",
    "    out.release()\n",
    "    \n",
    "    print(\"Video has been successfully created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обробка відео із Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 1000.jpg has less than 500 features!\n",
      "1 : 1001.jpg has less than 500 features!\n",
      "2 : 1002.jpg has less than 500 features!\n",
      "3 : 1003.jpg has less than 500 features!\n",
      "4 : 1004.jpg has less than 500 features!\n",
      "5 : 1005.jpg has less than 500 features!\n",
      "6 : 1006.jpg has less than 500 features!\n",
      "7 : 1007.jpg has less than 500 features!\n",
      "8 : 1008.jpg has less than 500 features!\n",
      "9 : 1009.jpg has less than 500 features!\n",
      "10 : 1010.jpg has less than 500 features!\n",
      "11 : 1011.jpg has less than 500 features!\n",
      "12 : 1012.jpg has less than 500 features!\n",
      "13 : 1013.jpg has less than 500 features!\n",
      "14 : 1014.jpg has less than 500 features!\n",
      "15 : 1015.jpg has less than 500 features!\n",
      "16 : 1016.jpg has less than 500 features!\n",
      "17 : 1017.jpg has less than 500 features!\n",
      "18 : 1018.jpg has less than 500 features!\n",
      "19 : 1019.jpg has less than 500 features!\n",
      "20 : 1020.jpg has less than 500 features!\n",
      "21 : 1021.jpg has less than 500 features!\n",
      "22 : 1022.jpg has less than 500 features!\n",
      "23 : 1023.jpg has less than 500 features!\n",
      "24 : 1024.jpg has less than 500 features!\n",
      "25 : 1025.jpg has less than 500 features!\n",
      "26 : 1026.jpg has less than 500 features!\n",
      "27 : 1027.jpg has less than 500 features!\n",
      "28 : 1028.jpg has less than 500 features!\n",
      "29 : 1029.jpg has less than 500 features!\n",
      "30 : 1030.jpg has less than 500 features!\n",
      "31 : 1031.jpg has less than 500 features!\n",
      "32 : 1032.jpg has less than 500 features!\n",
      "33 : 1033.jpg has less than 500 features!\n",
      "34 : 1034.jpg has less than 500 features!\n",
      "35 : 1035.jpg has less than 500 features!\n",
      "36 : 1036.jpg has less than 500 features!\n",
      "37 : 1037.jpg has less than 500 features!\n",
      "38 : 1038.jpg has less than 500 features!\n",
      "39 : 1039.jpg has less than 500 features!\n",
      "40 : 1040.jpg has less than 500 features!\n",
      "41 : 1041.jpg has less than 500 features!\n",
      "42 : 1042.jpg has less than 500 features!\n",
      "43 : 1043.jpg has less than 500 features!\n",
      "44 : 1044.jpg has less than 500 features!\n",
      "45 : 1045.jpg has less than 500 features!\n",
      "46 : 1046.jpg has less than 500 features!\n",
      "47 : 1047.jpg has less than 500 features!\n",
      "48 : 1048.jpg has less than 500 features!\n",
      "49 : 1049.jpg has less than 500 features!\n",
      "50 : 1050.jpg has less than 500 features!\n",
      "51 : 1051.jpg has less than 500 features!\n",
      "52 : 1052.jpg has less than 500 features!\n",
      "53 : 1053.jpg has less than 500 features!\n",
      "54 : 1054.jpg has less than 500 features!\n",
      "55 : 1055.jpg has less than 500 features!\n",
      "56 : 1056.jpg has less than 500 features!\n",
      "57 : 1057.jpg has less than 500 features!\n",
      "58 : 1058.jpg has less than 500 features!\n",
      "59 : 1059.jpg has less than 500 features!\n",
      "60 : 1060.jpg has less than 500 features!\n",
      "61 : 1061.jpg has less than 500 features!\n",
      "62 : 1062.jpg has less than 500 features!\n",
      "63 : 1063.jpg has less than 500 features!\n",
      "64 : 1064.jpg has less than 500 features!\n",
      "65 : 1065.jpg has less than 500 features!\n",
      "66 : 1066.jpg has less than 500 features!\n",
      "67 : 1067.jpg has less than 500 features!\n",
      "68 : 1068.jpg has less than 500 features!\n",
      "69 : 1069.jpg has less than 500 features!\n",
      "70 : 1070.jpg has less than 500 features!\n",
      "71 : 1071.jpg has less than 500 features!\n",
      "72 : 1072.jpg has less than 500 features!\n",
      "73 : 1073.jpg has less than 500 features!\n",
      "74 : 1074.jpg has less than 500 features!\n",
      "75 : 1075.jpg has less than 500 features!\n",
      "76 : 1076.jpg has less than 500 features!\n",
      "77 : 1077.jpg has less than 500 features!\n",
      "78 : 1078.jpg has less than 500 features!\n",
      "79 : 1079.jpg has less than 500 features!\n",
      "80 : 1080.jpg has less than 500 features!\n",
      "81 : 1081.jpg has less than 500 features!\n",
      "82 : 1082.jpg has less than 500 features!\n",
      "83 : 1083.jpg has less than 500 features!\n",
      "84 : 1084.jpg has less than 500 features!\n",
      "85 : 1085.jpg has less than 500 features!\n",
      "86 : 1086.jpg has less than 500 features!\n",
      "87 : 1087.jpg has less than 500 features!\n",
      "88 : 1088.jpg has less than 500 features!\n",
      "89 : 1089.jpg has less than 500 features!\n",
      "90 : 1090.jpg has less than 500 features!\n",
      "91 : 1091.jpg has less than 500 features!\n",
      "92 : 1092.jpg has less than 500 features!\n",
      "93 : 1093.jpg has less than 500 features!\n",
      "94 : 1094.jpg has less than 500 features!\n",
      "95 : 1095.jpg has less than 500 features!\n",
      "96 : 1096.jpg has less than 500 features!\n",
      "97 : 1097.jpg has less than 500 features!\n",
      "98 : 1098.jpg has less than 500 features!\n",
      "99 : 1099.jpg has less than 500 features!\n",
      "100 : 1100.jpg has less than 500 features!\n",
      "101 : 1101.jpg has less than 500 features!\n",
      "102 : 1102.jpg has less than 500 features!\n",
      "103 : 1103.jpg has less than 500 features!\n",
      "104 : 1104.jpg has less than 500 features!\n",
      "105 : 1105.jpg has less than 500 features!\n",
      "106 : 1106.jpg has less than 500 features!\n",
      "107 : 1107.jpg has less than 500 features!\n",
      "108 : 1108.jpg has less than 500 features!\n",
      "109 : 1109.jpg has less than 500 features!\n",
      "110 : 1110.jpg has less than 500 features!\n",
      "111 : 1111.jpg has less than 500 features!\n",
      "112 : 1112.jpg has less than 500 features!\n",
      "113 : 1113.jpg has less than 500 features!\n",
      "114 : 1114.jpg has less than 500 features!\n",
      "120 : 1120.jpg has less than 500 features!\n",
      "121 : 1121.jpg has less than 500 features!\n",
      "122 : 1122.jpg has less than 500 features!\n",
      "123 : 1123.jpg has less than 500 features!\n",
      "124 : 1124.jpg has less than 500 features!\n",
      "125 : 1125.jpg has less than 500 features!\n",
      "126 : 1126.jpg has less than 500 features!\n",
      "127 : 1127.jpg has less than 500 features!\n",
      "131 : 1131.jpg has less than 500 features!\n",
      "147 : 1147.jpg has less than 500 features!\n",
      "151 : 1151.jpg has less than 500 features!\n",
      "152 : 1152.jpg has less than 500 features!\n",
      "153 : 1153.jpg has less than 500 features!\n",
      "154 : 1154.jpg has less than 500 features!\n",
      "155 : 1155.jpg has less than 500 features!\n",
      "156 : 1156.jpg has less than 500 features!\n",
      "157 : 1157.jpg has less than 500 features!\n",
      "158 : 1158.jpg has less than 500 features!\n",
      "160 : 1160.jpg has less than 500 features!\n",
      "162 : 1162.jpg has less than 500 features!\n",
      "164 : 1164.jpg has less than 500 features!\n",
      "166 : 1166.jpg has less than 500 features!\n",
      "167 : 1167.jpg has less than 500 features!\n",
      "168 : 1168.jpg has less than 500 features!\n",
      "169 : 1169.jpg has less than 500 features!\n",
      "170 : 1170.jpg has less than 500 features!\n",
      "171 : 1171.jpg has less than 500 features!\n",
      "172 : 1172.jpg has less than 500 features!\n",
      "173 : 1173.jpg has less than 500 features!\n",
      "174 : 1174.jpg has less than 500 features!\n",
      "175 : 1175.jpg hasn't got any features!\n",
      "176 : 1176.jpg hasn't got any features!\n",
      "177 : 1177.jpg hasn't got any features!\n",
      "178 : 1178.jpg hasn't got any features!\n",
      "179 : 1179.jpg has less than 500 features!\n",
      "180 : 1180.jpg has less than 500 features!\n",
      "181 : 1181.jpg has less than 500 features!\n",
      "182 : 1182.jpg has less than 500 features!\n",
      "183 : 1183.jpg hasn't got any features!\n",
      "184 : 1184.jpg hasn't got any features!\n",
      "185 : 1185.jpg hasn't got any features!\n",
      "186 : 1186.jpg hasn't got any features!\n",
      "187 : 1187.jpg hasn't got any features!\n",
      "188 : 1188.jpg hasn't got any features!\n",
      "189 : 1189.jpg hasn't got any features!\n",
      "190 : 1190.jpg hasn't got any features!\n",
      "191 : 1191.jpg hasn't got any features!\n",
      "192 : 1192.jpg hasn't got any features!\n",
      "193 : 1193.jpg hasn't got any features!\n",
      "194 : 1194.jpg hasn't got any features!\n",
      "195 : 1195.jpg hasn't got any features!\n",
      "196 : 1196.jpg hasn't got any features!\n",
      "197 : 1197.jpg hasn't got any features!\n",
      "198 : 1198.jpg hasn't got any features!\n",
      "199 : 1199.jpg hasn't got any features!\n",
      "200 : 1200.jpg has less than 500 features!\n",
      "201 : 1201.jpg has less than 500 features!\n",
      "202 : 1202.jpg has less than 500 features!\n",
      "203 : 1203.jpg has less than 500 features!\n",
      "252 : 1252.jpg has less than 500 features!\n",
      "253 : 1253.jpg has less than 500 features!\n",
      "254 : 1254.jpg hasn't got any features!\n",
      "255 : 1255.jpg hasn't got any features!\n",
      "256 : 1256.jpg hasn't got any features!\n",
      "257 : 1257.jpg hasn't got any features!\n",
      "258 : 1258.jpg hasn't got any features!\n",
      "259 : 1259.jpg hasn't got any features!\n",
      "260 : 1260.jpg hasn't got any features!\n",
      "261 : 1261.jpg hasn't got any features!\n",
      "262 : 1262.jpg hasn't got any features!\n",
      "263 : 1263.jpg hasn't got any features!\n",
      "264 : 1264.jpg hasn't got any features!\n",
      "265 : 1265.jpg hasn't got any features!\n",
      "266 : 1266.jpg hasn't got any features!\n",
      "267 : 1267.jpg hasn't got any features!\n",
      "268 : 1268.jpg hasn't got any features!\n",
      "269 : 1269.jpg hasn't got any features!\n",
      "270 : 1270.jpg hasn't got any features!\n",
      "271 : 1271.jpg hasn't got any features!\n",
      "272 : 1272.jpg hasn't got any features!\n",
      "273 : 1273.jpg hasn't got any features!\n",
      "274 : 1274.jpg hasn't got any features!\n",
      "275 : 1275.jpg hasn't got any features!\n",
      "276 : 1276.jpg hasn't got any features!\n",
      "277 : 1277.jpg hasn't got any features!\n",
      "278 : 1278.jpg hasn't got any features!\n",
      "279 : 1279.jpg hasn't got any features!\n",
      "280 : 1280.jpg hasn't got any features!\n",
      "281 : 1281.jpg has less than 500 features!\n",
      "282 : 1282.jpg has less than 500 features!\n",
      "283 : 1283.jpg has less than 500 features!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284 : 1284.jpg has less than 500 features!\n",
      "290 : 1290.jpg has less than 500 features!\n",
      "302 : 1302.jpg has less than 500 features!\n",
      "522 : 1522.jpg has less than 500 features!\n",
      "523 : 1523.jpg has less than 500 features!\n",
      "527 : 1527.jpg has less than 500 features!\n",
      "535 : 1535.jpg has less than 500 features!\n",
      "540 : 1540.jpg has less than 500 features!\n",
      "543 : 1543.jpg has less than 500 features!\n",
      "544 : 1544.jpg has less than 500 features!\n",
      "545 : 1545.jpg has less than 500 features!\n",
      "546 : 1546.jpg has less than 500 features!\n",
      "547 : 1547.jpg has less than 500 features!\n",
      "548 : 1548.jpg has less than 500 features!\n",
      "549 : 1549.jpg has less than 500 features!\n",
      "550 : 1550.jpg has less than 500 features!\n",
      "568 : 1568.jpg has less than 500 features!\n",
      "569 : 1569.jpg has less than 500 features!\n",
      "570 : 1570.jpg has less than 500 features!\n",
      "571 : 1571.jpg has less than 500 features!\n",
      "572 : 1572.jpg has less than 500 features!\n",
      "573 : 1573.jpg has less than 500 features!\n",
      "574 : 1574.jpg has less than 500 features!\n",
      "575 : 1575.jpg has less than 500 features!\n",
      "576 : 1576.jpg has less than 500 features!\n",
      "577 : 1577.jpg has less than 500 features!\n",
      "578 : 1578.jpg has less than 500 features!\n",
      "579 : 1579.jpg has less than 500 features!\n",
      "580 : 1580.jpg hasn't got any features!\n",
      "581 : 1581.jpg has less than 500 features!\n",
      "582 : 1582.jpg has less than 500 features!\n",
      "583 : 1583.jpg has less than 500 features!\n",
      "584 : 1584.jpg has less than 500 features!\n",
      "585 : 1585.jpg has less than 500 features!\n",
      "586 : 1586.jpg has less than 500 features!\n",
      "587 : 1587.jpg has less than 500 features!\n",
      "588 : 1588.jpg has less than 500 features!\n",
      "589 : 1589.jpg has less than 500 features!\n",
      "590 : 1590.jpg has less than 500 features!\n",
      "591 : 1591.jpg has less than 500 features!\n",
      "592 : 1592.jpg has less than 500 features!\n",
      "593 : 1593.jpg has less than 500 features!\n",
      "594 : 1594.jpg has less than 500 features!\n",
      "595 : 1595.jpg has less than 500 features!\n",
      "596 : 1596.jpg has less than 500 features!\n",
      "597 : 1597.jpg has less than 500 features!\n",
      "598 : 1598.jpg has less than 500 features!\n",
      "599 : 1599.jpg has less than 500 features!\n",
      "600 : 1600.jpg has less than 500 features!\n",
      "601 : 1601.jpg has less than 500 features!\n",
      "602 : 1602.jpg has less than 500 features!\n",
      "603 : 1603.jpg has less than 500 features!\n",
      "604 : 1604.jpg has less than 500 features!\n",
      "605 : 1605.jpg has less than 500 features!\n",
      "606 : 1606.jpg has less than 500 features!\n",
      "607 : 1607.jpg has less than 500 features!\n",
      "608 : 1608.jpg hasn't got any features!\n",
      "609 : 1609.jpg hasn't got any features!\n",
      "610 : 1610.jpg has less than 500 features!\n",
      "611 : 1611.jpg has less than 500 features!\n",
      "612 : 1612.jpg has less than 500 features!\n",
      "613 : 1613.jpg has less than 500 features!\n",
      "614 : 1614.jpg has less than 500 features!\n",
      "615 : 1615.jpg has less than 500 features!\n",
      "616 : 1616.jpg has less than 500 features!\n",
      "617 : 1617.jpg has less than 500 features!\n",
      "618 : 1618.jpg has less than 500 features!\n",
      "619 : 1619.jpg has less than 500 features!\n",
      "620 : 1620.jpg has less than 500 features!\n",
      "621 : 1621.jpg has less than 500 features!\n",
      "622 : 1622.jpg has less than 500 features!\n",
      "623 : 1623.jpg has less than 500 features!\n",
      "624 : 1624.jpg has less than 500 features!\n",
      "625 : 1625.jpg has less than 500 features!\n",
      "626 : 1626.jpg has less than 500 features!\n",
      "627 : 1627.jpg has less than 500 features!\n",
      "628 : 1628.jpg has less than 500 features!\n",
      "629 : 1629.jpg has less than 500 features!\n",
      "630 : 1630.jpg has less than 500 features!\n",
      "631 : 1631.jpg has less than 500 features!\n",
      "632 : 1632.jpg has less than 500 features!\n",
      "633 : 1633.jpg has less than 500 features!\n",
      "634 : 1634.jpg has less than 500 features!\n",
      "635 : 1635.jpg has less than 500 features!\n",
      "636 : 1636.jpg has less than 500 features!\n",
      "637 : 1637.jpg has less than 500 features!\n",
      "638 : 1638.jpg has less than 500 features!\n",
      "639 : 1639.jpg has less than 500 features!\n",
      "\n",
      "X_test_video shape: (346, 16000)\n"
     ]
    }
   ],
   "source": [
    "X_test_video, ids_lr, ids_for_zero_lr = create_X_for_lr(500, \"video_frames\")\n",
    "\n",
    "print()\n",
    "print(\"X_test_video shape:\", X_test_video.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.jpg has less than 500 features!\n",
      "171.jpg has less than 500 features!\n",
      "172.jpg has less than 500 features!\n",
      "174.jpg has less than 500 features!\n",
      "175.jpg has less than 500 features!\n",
      "176.jpg has less than 500 features!\n",
      "178.jpg has less than 500 features!\n",
      "202.jpg has less than 500 features!\n",
      "203.jpg has less than 500 features!\n",
      "204.jpg has less than 500 features!\n",
      "225.jpg has less than 500 features!\n",
      "236.jpg has less than 500 features!\n",
      "239.jpg has less than 500 features!\n",
      "240.jpg has less than 500 features!\n",
      "241.jpg hasn't got any features!\n",
      "246.jpg has less than 500 features!\n",
      "255.jpg has less than 500 features!\n",
      "258.jpg has less than 500 features!\n",
      "259.jpg has less than 500 features!\n",
      "263.jpg has less than 500 features!\n",
      "264.jpg has less than 500 features!\n",
      "265.jpg has less than 500 features!\n",
      "267.jpg hasn't got any features!\n",
      "268.jpg has less than 500 features!\n",
      "269.jpg hasn't got any features!\n",
      "30.jpg has less than 500 features!\n",
      "34.jpg has less than 500 features!\n",
      "35.jpg has less than 500 features!\n",
      "36.jpg has less than 500 features!\n",
      "38.jpg has less than 500 features!\n",
      "39.jpg hasn't got any features!\n",
      "46.jpg hasn't got any features!\n",
      "47.jpg has less than 500 features!\n",
      "58.jpg has less than 500 features!\n",
      "59.jpg has less than 500 features!\n",
      "72.jpg has less than 500 features!\n",
      "82.jpg has less than 500 features!\n",
      "83.jpg has less than 500 features!\n",
      "84.jpg has less than 500 features!\n",
      "85.jpg has less than 500 features!\n",
      "86.jpg has less than 500 features!\n",
      "87.jpg has less than 500 features!\n",
      "88.jpg has less than 500 features!\n",
      "91.jpg hasn't got any features!\n",
      "92.jpg hasn't got any features!\n",
      "93.jpg hasn't got any features!\n",
      "94.jpg has less than 500 features!\n",
      "95.jpg has less than 500 features!\n",
      "\n",
      "X shape: (221, 16000)\n",
      "y shape: (221,)\n"
     ]
    }
   ],
   "source": [
    "X, y, X_dict = create_X_and_y(n_features, directory_test, include_other_photos=True)\n",
    "\n",
    "print()\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = logreg.predict(X_test_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1,\n",
       "       1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2,\n",
       "       1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1,\n",
       "       2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2,\n",
       "       2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "       1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_with_zeros_lr = add_zeros(y_pred_lr, ids_lr, ids_for_zero_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
       "       2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "       1, 1, 2, 1, 0, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1,\n",
       "       2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2,\n",
       "       1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1,\n",
       "       2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "       1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1,\n",
       "       1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0,\n",
       "       2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 2, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_with_zeros_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABrUAAAI/CAYAAADZUlJ9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdfaxk510f8O8v603ZUuR16gut1744SJYDBZLQkUOVSthVsQ1qSUor1RGFgIgWIaXvshpaFUtJJVBdtRIiJbjFSisVpxIkYYsIJiVJ00Ij+S5J877EuFRZL1Jc7IVSr8h6efrHzrrD9dyZM3Nn7n1m7+cjjXbnOW/PeV7OOeuvZ6ZaawEAAAAAAICeveywKwAAAAAAAADzCLUAAAAAAADonlALAAAAAACA7gm1AAAAAAAA6J5QCwAAAAAAgO4JtQAAAAAAAOjeDYddgWluvvnmdvvttx92NQAAAAAAADhgZ8+e/d+tta3d5V2GWrfffnt2dnYOuxoAAAAAAAAcsKr6X9PKff0gAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0L25oVZV3VZVH66qz1XVZ6rq705Zp6rqJ6rqyar6ZFV9y8SyN1fVF8avN6/6BAAAAAAAALj+3TBgnReS/MPW2m9U1VclOVtVH2ytfXZine9Icsf49bokP5XkdVX1iiQPJRklaeNtz7TWnlvpWQCwsd7/8afz8OPncuHipdxy8kQevO/OvPG1pzZm/wdt2vkkGVS2yee96Xb32z2v2sqHP//M4D7bhHG8aB2XPadVzIFNaM9NM69NZy2/tuzpi5dyrCpXWsupXf04a9m8ftxvfw8dc0PG17LLhtZx2TacXHbyxPFUJRefv7zn9Wro3L5xvK/nnr+80LEn15+1bFrZKve/6LGXXXZqxlhYdxsOmU/TxteibTLtONPOrYf+2KRj7zVv9xofPZzHomNhkTF62OPqoMfC0Ov0rHvEfp9/5t0jb5wyNpd93pt1v5w2PhadA7PaZlobruP6tt/5sY4+HtrmQ/99M6Su0+b0tDHkmR6OrmqtLbZB1S8k+cnW2gcnyn46yUdaa4+N359Lcve1V2vth6att5fRaNR2dnYWqhcAm+f9H386P/LeT+XS5Ssvlp04fiw/9t3ftLKH73Xu/6BNO5/jL6ukkstX2syyTT7vTTet33ab1WdJuh/Hi861ZefmKuZA0n97bpp5/TlrefLS/rhmWj/OWjatH/d7Hxg65oaMr2WXzavnrGvMom04xKJze5pljz3Uuve/DkPmxKRVnuOiY3qVx2E9em/rRet3UGP0ejHvHjxtvWUMvUcuesxFnxuGPgsuYmgbrup4+9nXrPVX8Yy7TD/vtc6Quiaz57Rnejhaqupsa230kvJFQq2quj3JR5N8Y2vt9yfKfzHJj7fW/tv4/a8m+Ue5Gmp9RWvtn43L/2mSS621fzHrOEItgKPh9T/+oTx98dJLyk+dPJFfe9tf6n7/B22v8xlqU8970+2n306dPJEk3Y/jRefasnNzFXMg6b89N828/py1PJneH8va3Y/7vQ8sMubmja9ll82r537nxTIWndsMs445sR+91Qd2M0b3Nu8evHu9ZSx7zV/2ee+g+3toG/Zuv8+4B3n+Q/vYMz0cHXuFWkO+fvDaDv5Ukp9P8vcmA61ri6ds0maUT9v/6SSnk2R7e3totQDYYBf2eFjdq7y3/R+0/dZ7U8970+2n3Wdt21N/LjrXlp2b65wDPbXnppnXnwd5Ld69z/0ee5E6Lju+9jsuD2PsXm/311701n691Qd2M0b3Nu8evHu9/Rxj1dv1co8Z2oa926R/Q67i+WzT+wsY5mVDVqqq47kaaP2H1tp7p6xyPsltE+9vTXJhRvlLtNYeaa2NWmujra2tIdUCYMPdMv4/rIaW97b/g7bfem/qeW+6/bT7LSdPbMQ4XrSOy57TKubAJrTnppnXprOWr7rdd+9vv/29SP3mja9ll62yjqtiHq3HOubEfvRWH9jNGN3bvHvw7vX2c4xVb3eQzw1D6rHpY2yT/g05tI890wNzQ62qqiQ/k+RzrbV/ucdqZ5J8X131rUl+r7X2O0keT3JvVd1UVTcluXdcBgB58L47c+L4sT9WduL4sRd/QLb3/R+0aedz/GWV48dqbtkmn/emm9Zvu83qs00Yx4vWcdlzWsUc2IT23DTz2nTW8lnzY1o/zlo2rR/3299Dx9yQ8bXssmXqOKuuQ5bNsujcXuWxh1r3/tdhyJyYtMpzXHRMr/I4rEfvbb1o/Q5qjF4v5t2Dp623jKH3yEWPuej9cuiz4CKGtuGqjreffc1afxXPuMv0817rDKnrvPb2TA8kw75+8PVJvjfJp6rqE+Oyf5xkO0laa+9K8ktJvjPJk0meT/ID42XPVtU7kjwx3u7trbVnV1d9ADbZtR9wffjxc7lw8VJuOXkiD95358p+2HXd+z9oe53P0LJNPe9NN63f7nnVVj78+WcW6rOe+3PRubbs3FzlHOi5PTfNvP4c0t8PP34uT1+8lGNVudJaTu3qx1nLZvXjfu8Di4y5oeNr1eNyso7LtuHkspMnjqcqufj85T2vV0Pn9o3jfT33/OWFjj25/qxl08pWuf9Fj73sslMzxsK623DofBpynFnHnnacaefWQ39s0rH3mrd7jY8ezmPRsbDIGD3scXXQY2HIdXrePWI/zz9D7pE3Thmbyz7vzbpfziobOgf2apu92nAd17f9zo9V9/HQfl7k3zdD6zp0DHmmh6OpWpv6E1eHajQatZ2dncOuBgAAAAAAAAesqs621ka7ywf9phYAAAAAAAAcJqEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANC9G+atUFWPJvkrSb7UWvvGKcsfTPI9E/v7+iRbrbVnq+q3k/yfJFeSvNBaG62q4gAAAAAAABwdQz6p9e4k9++1sLX2cGvtNa211yT5kST/pbX27MQq94yXC7QAAAAAAABYytxQq7X20STPzltv7E1JHttXjQAAAAAAAGCXlf2mVlX9yVz9RNfPTxS3JL9SVWer6vSqjgUAAAAAAMDRMvc3tRbwV5P82q6vHnx9a+1CVX11kg9W1efHn/x6iXHodTpJtre3V1gtAAAAAAAANt3KPqmV5IHs+urB1tqF8Z9fSvK+JHfttXFr7ZHW2qi1Ntra2lphtQAAAAAAANh0Kwm1qurGJN+W5Bcmyr6yqr7q2t+T3Jvk06s4HgAAAAAAAEfL3K8frKrHktyd5OaqOp/koSTHk6S19q7xan8tya+01v7vxKZfk+R9VXXtOD/bWvvl1VUdAAAAAACAo2JuqNVae9OAdd6d5N27yp5K8uplKwYAAAAAAADXrPI3tQAAAAAAAGAthFoAAAAAAAB0T6gFAAAAAABA94RaAAAAAAAAdE+oBQAAAAAAQPeEWgAAAAAAAHRPqAUAAAAAAED3hFoAAAAAAAB0T6gFAAAAAABA94RaAAAAAAAAdE+oBQAAAAAAQPeEWgAAAAAAAHRPqAUAAAAAAED3hFoAAAAAAAB0T6gFAAAAAABA94RaAAAAAAAAdE+oBQAAAAAAQPeEWgAAAAAAAHRPqAUAAAAAAED3hFoAAAAAAAB0T6gFAAAAAABA94RaAAAAAAAAdE+oBQAAAAAAQPeEWgAAAAAAAHRPqAUAAAAAAED3hFoAAAAAAAB0T6gFAAAAAABA94RaAAAAAAAAdE+oBQAAAAAAQPeEWgAAAAAAAHRPqAUAAAAAAED3hFoAAAAAAAB0T6gFAAAAAABA94RaAAAAAAAAdE+oBQAAAAAAQPeEWgAAAAAAAHRPqAUAAAAAAED3hFoAAAAAAAB0T6gFAAAAAABA94RaAAAAAAAAdE+oBQAAAAAAQPeEWgAAAAAAAHRPqAUAAAAAAED3hFoAAAAAAAB0T6gFAAAAAABA94RaAAAAAAAAdE+oBQAAAAAAQPeEWgAAAAAAAHRPqAUAAAAAAED3hFoAAAAAAAB0T6gFAAAAAABA94RaAAAAAAAAdG9uqFVVj1bVl6rq03ssv7uqfq+qPjF+/ejEsvur6lxVPVlVb1tlxQEAAAAAADg6hnxS691J7p+zzn9trb1m/Hp7klTVsSTvTPIdSb4hyZuq6hv2U1kAAAAAAACOprmhVmvto0meXWLfdyV5srX2VGvty0nek+QNS+wHAAAAAACAI25Vv6n1F6rqf1TVB6rqz43LTiX54sQ658dlAAAAAAAAsJAbVrCP30jyta21P6iq70zy/iR3JKkp67a9dlJVp5OcTpLt7e0VVAsAAAAAAIDrxb4/qdVa+/3W2h+M//5LSY5X1c25+sms2yZWvTXJhRn7eaS1Nmqtjba2tvZbLQAAAAAAAK4j+w61qurPVFWN/37XeJ+/m+SJJHdU1Sur6uVJHkhyZr/HAwAAAAAA4OiZ+/WDVfVYkruT3FxV55M8lOR4krTW3pXkbyT54ap6IcmlJA+01lqSF6rqrUkeT3IsyaOttc+s5SwAAAAAAAC4rtXV/Kkvo9Go7ezsHHY1AAAAAAAAOGBVdba1Ntpdvu+vHwQAAAAAAIB1E2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN2bG2pV1aNV9aWq+vQey7+nqj45fv16Vb16YtlvV9WnquoTVbWzyooDAAAAAABwdAz5pNa7k9w/Y/n/TPJtrbVvTvKOJI/sWn5Pa+01rbXRclUEAAAAAADgqLth3gqttY9W1e0zlv/6xNuPJbl1/9UCAAAAAACA/2/Vv6n1g0k+MPG+JfmVqjpbVadXfCwAAAAAAACOiLmf1Bqqqu7J1VDrL04Uv761dqGqvjrJB6vq8621j+6x/ekkp5Nke3t7VdUCAAAAAADgOrCST2pV1Tcn+bdJ3tBa+91r5a21C+M/v5TkfUnu2msfrbVHWmuj1tpoa2trFdUCAAAAAADgOrHvUKuqtpO8N8n3ttZ+c6L8K6vqq679Pcm9ST693+MBAAAAAABw9Mz9+sGqeizJ3UlurqrzSR5KcjxJWmvvSvKjSf50kn9dVUnyQmttlORrkrxvXHZDkp9trf3yGs4BAAAAAACA69zcUKu19qY5y9+S5C1Typ9K8urlqwYAAAAAAABXreQ3tQAAAAAAAGCdhFoAAAAAAAB0T6gFAAAAAABA94RaAAAAAAAAdE+oBQAAAAAAQPeEWgAAAAAAAHRPqAUAAAAAAED3hFoAAAAAAAB0T6gFAAAAAABA94RaAAAAAAAAdE+oBQAAAAAAQPeEWgAAAAAAAHRPqAUAAAAAAED3hFoAAAAAAAB0T6gFAAAAAABA94RaAAAAAAAAdE+oBQAAAAAAQPeEWgAAAAAAAHRPqAUAAAAAAED3hFoAAAAAAAB0T6gFAAAAAABA94RaAAAAAAAAdE+oBQAAAAAAQPeEWgAAAAAAAHRPqAUAAAAAAED3hFoAAAAAAAB0T6gFAAAAAABA94RaAAAAAAAAdE+oBQAAAAAAQPeEWgAAAAAAAHRPqAUAAAAAAED3hFoAAAAAAAB0T6gFAAAAAABA94RaAAAAAAAAdE+oBQAAAAAAQPeEWgAAAAAAAHRPqAUAAAAAAED3hFoAAAAAAAB0T6gFAAAAAABA94RaAAAAAAAAdE+oBQAAAAAAQPeEWgAAAAAAAHRPqAUAAAAAAED3hFoAAAAAAAB0T6gFAAAAAABA94RaAAAAAAAAdE+oBQAAAAAAQPeEWgAAAAAAAHRPqAUAAAAAAED3hFoAAAAAAAB0T6gFAAAAAABA94RaAAAAAAAAdG9QqFVVj1bVl6rq03ssr6r6iap6sqo+WVXfMrHszVX1hfHrzauqOAAAAAAAAEfHDQPXe3eSn0zy7/dY/h1J7hi/Xpfkp5K8rqpekeShJKMkLcnZqjrTWntuP5UGYDXe//Gn8/Dj5/L0xUs5VpUrrb3458kTx1OVPPf85RfLTp08kQfvuzNvfO2plR37wsVLueXkidzzqq18+PPPvPj+wfvuTJKX1G9avaaV7a7zOvZ14eKl3LjGdtrdRqtqe9Zj1nyaNnZ2j/N5Y3/WWF52TK9i/UXnx37n5sXnL8+9ZuynLVd5nTuqps2FWXNgd1vPu/bNun8MuSZPbj9rjO4ec9PqP+3Y08bo7mXLjM0h82/aOQ5pw6H9MLRes+bROu9tm3rfnDVn1t2GQ+bT5Lhd1XE2pW82zSa086J1PKgxuomGXqcXvQ8u+iw45B4/7Tq37HPlos+CR2lMrNusMbdM2azxMWTcHtW5DyTVWhu2YtXtSX6xtfaNU5b9dJKPtNYeG78/l+Tua6/W2g9NW28vo9Go7ezsDD4JABb3/o8/nR9576dy6fKVhbY7cfxYfuy7v2lfD41Djn38ZZVUcvnKsPvULIexr/2207Q2WkXbsx7LjumhZUOW9WDR+q17bi7bluba8mbNhWltvrut51379nvvSrLU9nvVf1nrmOezznFeGw7ph0XrNW0erfPetqn3zVljet1tuOh8WuVxNqFvNs0mtPOidTyoMbqJFr1Or+I+OMuse/yyx1zFc+VRGhPrNnTMDS0bMj6GjiH9DNevqjrbWhvtLl/Vb2qdSvLFiffnx2V7lQNwyB5+/NxS/5i5dPlKHn783NqPffmP2sr+w/1h7Gu/7TStjVbR9qzHsmN6aNmQZT1YtH7rnpvLtqW5trxZc2Fam+9u63nXvv3eu5bdPjm4e8myx5l1jvPacEg/LFqvafNonfe2Tb1vzhqT627DRefDKo+zCX2zaTahnRet40GN0U206HV6FffBWWbd45c95iqeK4/SmFi3oWNuaNmQ8TF0DOlnOHqGfv3gPDWlrM0of+kOqk4nOZ0k29vbK6oWAHu5cPHSoWy7iu03xTra+Ki03abRL9cffbqcZdptcpt5177DvHdtglnnOK8Nh/TDfuuzznvbpt4359VvnW142Nv03jebZhPaedE6HtQY3USb0jY99EcPdbgerKMdh+xz6HH1Mxwtq/qk1vkkt028vzXJhRnlL9Fae6S1Nmqtjba2tlZULQD2csvJE4ey7Sq23xTraOOj0nabRr9cf/TpcpZpt8lt5l379ntdvd77ddY5zmvDIf2wTH1mvV/l8Tb1vjmvfutsw8Pepve+2TSb0M6L1vGgxugmWrZtDrp9erj3HvbxrxfraMch42PoGNLPcLSsKtQ6k+T76qpvTfJ7rbXfSfJ4knur6qaquinJveMyAA7Zg/fdmRPHjy283Ynjx178odd1Hvv4yyrHj037wO/iDmNf+22naW20irZnPZYd00PLhizrwaL1W/fcXLYtzbXlzZoL09p8d1vPu/bt99617PbJwd1Llj3OrHOc14ZD+mHRek2bR+u8t23qfXPWmFx3Gy46H1Z5nE3om02zCe28aB0PaoxuokWv06u4D84y6x6/7DFX8Vx5lMbEug0dc0PLhoyPoWNIP8PRM+jrB6vqsSR3J7m5qs4neSjJ8SRprb0ryS8l+c4kTyZ5PskPjJc9W1XvSPLEeFdvb609u8oTAGA5135E9eHHz+Xpi5dyrCpXWnvxz5Mnjqcqee75yy+WnTp5Ig/ed+e+f4B18tgXLl7KLSdP5J5XbeXDn3/mxffXHkp3129avaaV7a7zOvZ14eKl3LimdprWRqtoe9Zj3nyaNnZ2j/N5Y3/WWF52TK9i/UXnx37n5sXnL8+9ZuynLVd1nTuq9poLs+bAZFvPu/bNu38MvSYPGaO7x9y0+k879rQxunvZMmNzyPybdo5D2nBoPwyt117zaJ33tk29b86bM+tsw6HzaXLcruo4m9A3m2YT2nnROh7UGN1Ei1ynF70PLvosOPQev8x9bVpdF30WPCpjYt3mjbllymaNjyHj9ijOfeCqaq2/HxsfjUZtZ2fnsKsBAAAAAADAAauqs6210e7yVX39IAAAAAAAAKyNUAsAAAAAAIDuCbUAAAAAAADonlALAAAAAACA7gm1AAAAAAAA6J5QCwAAAAAAgO4JtQAAAAAAAOieUAsAAAAAAIDuCbUAAAAAAADonlALAAAAAACA7gm1AAAAAAAA6J5QCwAAAAAAgO4JtQAAAAAAAOieUAsAAAAAAIDuCbUAAAAAAADonlALAAAAAACA7gm1AAAAAAAA6J5QCwAAAAAAgO4JtQAAAAAAAOieUAsAAAAAAIDuCbUAAAAAAADonlALAAAAAACA7gm1AAAAAAAA6J5QCwAAAAAAgO4JtQAAAAAAAOieUAsAAAAAAIDuCbUAAAAAAADonlALAAAAAACA7gm1AAAAAAAA6J5QCwAAAAAAgO4JtQAAAAAAAOieUAsAAAAAAIDuCbUAAAAAAADonlALAAAAAACA7gm1AAAAAAAA6J5QCwAAAAAAgO4JtQAAAAAAAOieUAsAAAAAAIDuCbUAAAAAAADonlALAAAAAACA7gm1AAAAAAAA6J5QCwAAAAAAgO4JtQAAAAAAAOieUAsAAAAAAIDuCbUAAAAAAADonlALAAAAAACA7gm1AAAAAAAA6J5QCwAAAAAAgO4JtQAAAAAAAOieUAsAAAAAAIDuCbUAAAAAAADonlALAAAAAACA7g0Ktarq/qo6V1VPVtXbpiz/V1X1ifHrN6vq4sSyKxPLzqyy8gAAAAAAABwNN8xboaqOJXlnkm9Pcj7JE1V1prX22WvrtNb+/sT6fzvJayd2cam19prVVRkAAAAAAICjZsgnte5K8mRr7anW2peTvCfJG2as/6Ykj62icgAAAAAAAJAMC7VOJfnixPvz47KXqKqvTfLKJB+aKP6Kqtqpqo9V1RuXrikAAAAAAABH1tyvH0xSU8raHus+kOTnWmtXJsq2W2sXqurrknyoqj7VWvutlxyk6nSS00myvb09oFoAAAAAAAAcFUM+qXU+yW0T729NcmGPdR/Irq8ebK1dGP/5VJKP5I//3tbkeo+01kattdHW1taAagEAAAAAAHBUDAm1nkhyR1W9sqpenqvB1ZndK1XVnUluSvLfJ8puqqo/Mf77zUlen+Szq6g4AAAAAAAAR8fcrx9srb1QVW9N8niSY0keba19pqrenmSntXYt4HpTkve01ia/mvDrk/x0Vf1RrgZoP95aE2oBAAAAAACwkPrjGVQfRqNR29nZOexqAAAAAAAAcMCq6mxrbbS7fMjXDwIAAAAAAMChEmoBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAO08WGMAABOGSURBVAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0bFGpV1f1Vda6qnqyqt01Z/v1V9UxVfWL8esvEsjdX1RfGrzevsvIAAAAAAAAcDTfMW6GqjiV5Z5JvT3I+yRNVdaa19tldq/7H1tpbd237iiQPJRklaUnOjrd9biW1BwAAAAAA4EgY8kmtu5I82Vp7qrX25STvSfKGgfu/L8kHW2vPjoOsDya5f7mqAgAAAAAAcFQNCbVOJfnixPvz47Ld/npVfbKqfq6qbltwWwAAAAAAANjTkFCrppS1Xe//U5LbW2vfnOQ/J/l3C2x7dcWq01W1U1U7zzzzzIBqAQAAAAAAcFQMCbXOJ7lt4v2tSS5MrtBa+93W2h+O3/6bJH9+6LYT+3iktTZqrY22traG1B0AAAAAAIAjYkio9USSO6rqlVX18iQPJDkzuUJV/dmJt9+V5HPjvz+e5N6quqmqbkpy77gMAAAAAAAABrth3gqttReq6q25GkYdS/Joa+0zVfX2JDuttTNJ/k5VfVeSF5I8m+T7x9s+W1XvyNVgLEne3lp7dg3nAQAAAAAAwHWsWpv6E1eHajQatZ2dncOuBgAAAAAAAAesqs621ka7y4d8/SAAAAAAAAAcKqEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0TagEAAAAAANA9oRYAAAAAAADdE2oBAAAAAADQPaEWAAAAAAAA3RNqAQAAAAAA0D2hFgAAAAAAAN0bFGpV1f1Vda6qnqyqt01Z/g+q6rNV9cmq+tWq+tqJZVeq6hPj15lVVh4AAAAAAICj4YZ5K1TVsSTvTPLtSc4neaKqzrTWPjux2seTjFprz1fVDyf550n+5njZpdbaa1ZcbwAAAAAAAI6QIZ/UuivJk621p1prX07yniRvmFyhtfbh1trz47cfS3LraqsJAAAAAADAUTYk1DqV5IsT78+Py/byg0k+MPH+K6pqp6o+VlVvXKKOAAAAAAAAHHFzv34wSU0pa1NXrPpbSUZJvm2ieLu1dqGqvi7Jh6rqU62135qy7ekkp5Nke3t7QLUAAAAAAAA4KoZ8Uut8ktsm3t+a5MLularqLyf5J0m+q7X2h9fKW2sXxn8+leQjSV477SCttUdaa6PW2mhra2vwCQAAAAAAAHD9GxJqPZHkjqp6ZVW9PMkDyf9r735jZDvrOoB/f9zelisoF8rVyC21JdQCBtuSjSnBEP6orUqgISXWSCSEpG8gwaiY1jcqCUHSRNRICARQNP6hVsAbX1CRYvSFFm4tCm1prAThUqCYtviHBtry88WcS7fL3r2z292dZ3Y/n2Szc5555pxnZud3zjPz3TmTY6s7VNUlSd6VWaB1z6r2J1fVWdPlpyZ5QZLbt2vwAAAAAAAA7A+nPf1gdz9UVW9IcmOSA0ne1923VdWbkxzv7mNJrkvyxCR/WVVJ8oXufnmSZyd5V1V9O7MA7be7W6gFAAAAAADAplT3ul+PtVArKyt9/PjxRQ8DAAAAAACAXVZVt3T3ytr2eU4/CAAAAAAAAAsl1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhjdXqFVVl1fVnVV1V1Vds871Z1XVB6brb66q81Zdd+3UfmdVXbZ9QwcAAAAAAGC/OON0HarqQJJ3JPnJJCeSfLKqjnX37au6vS7Jfd39zKq6KsnbkvxcVT0nyVVJfiTJ05L8XVX9cHc/vN13ZD/68K1fynU33pkv3f9ADlTl4e7v/D586GCqkvu+8eCGbVu9bqf7j7qu/bpt92OsbW/nuo4ePpQ3XXZhrrjk6Nz7nLvvfyBP2uFtr97W0zYxxp02z7hO9zht9u938nFK8qhtv/hZR/Lxz37tUWNZ22d12+pjxWjPw71Sm5upJ8a13vxqvz6nd+uYslv7+VGPLQDAONabC+7Wa9fNrmuj/tsxpz3Zdv83Hhx67rTd71Xslbn5Xtn2Xrsf3jfYHtXdG3eoen6S3+zuy6bla5Oku9+6qs+NU59/qqozknwlyZEk16zuu7rfRttcWVnp48ePb/lO7QcfvvVLufaDn84DD8oHgcfm0MEDeesrn3vayfJO7HPW2/Z625pnjDttnnHt1ON08HGVVPLgw6c+Zq/XZ57bsb1GeK6ydeZXj91Wjyk7XTujHlsAgHFsNBfc6deum13XRv2T7Nrr90Uzf2cZjVhLo6qqW7p7ZW37PKcfPJrki6uWT0xt6/bp7oeSfD3J2XPeli247sY77bCBbfHAgw/nuhvv3LDPTu1z1tv2etuaZ4w7bZ5x7dTj9OC3+7TB1Hp95rkd22uE5ypbZ3712G31mLLTtTPqsQUAGMdGc8Gdfu262XVt1H83X78vmvk7y2jEWlo2pz39YJJap23tO2Sn6jPPbWcrqLo6ydVJcu65584xrP3t7vsfWPQQgD3kdPuUndznrF33qba16P3ePONa9BgZg+fB8vK32x5bPabs5rFmN7YJACyXzc5htnN+sdl1LWpuM9rcabTxwLw8dx+beT6pdSLJ01ctn5Pk7lP1mU4/+KQk98552yRJd7+7u1e6e+XIkSPzjX4fe9rhQ4seArCHnG6fspP7nLXrPtW2Fr3fm2dcix4jY/A8WF7+dttjq8eU3TzW7MY2AYDlstk5zHbOLza7ro3aFzGnWpTRxgPz8tx9bOYJtT6Z5IKqOr+qzkxyVZJja/ocS/Ka6fKVSW7q2Zd1HUtyVVWdVVXnJ7kgySe2Z+j725suuzCHDh5Y9DCAPeDQwQN502UXbthnp/Y56217vW3NM8adNs+4dupxOvi4ysED6334eeM+89yO7TXCc5WtM7967LZ6TNnp2hn12AIAjGOjueBOv3bd7Lo26r+br98XzfydZTRiLS2b04Za03dkvSHJjUnuSHJ9d99WVW+uqpdP3d6b5OyquivJLye5ZrrtbUmuT3J7ko8keX13O9HpNrjikqN56yufm6NTqnug6lG/Dx86mCd/z8HTtm31up3uP+q69uu23Y+xtr2d6zp6+NBcX065ep9TO7zttduad4w7bZ5xzfM4bfbvd/TwoVz3qoty3ZUXPWrbr7703Ectr9dnddtWtr2Mz+llqCfGdar51X59Tu/WMWU3amfUYwsAMI5TzQV347XrZte1Uf/tmtOebBt57rQT71Xslbn5Xtn2Xrsfo9bSsqnZB6rGsrKy0sePH1/0MAAAAAAAANhlVXVLd6+sbZ/n9IMAAAAAAACwUEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHjV3Ysew3epqq8l+c9Fj2OJPDXJfy16EMCmqFtYPuoWlo+6heWjbmH5qFtYTmqX0f1Qdx9Z2zhkqMXmVNXx7l5Z9DiA+albWD7qFpaPuoXlo25h+ahbWE5ql2Xl9IMAAAAAAAAMT6gFAAAAAADA8IRae8O7Fz0AYNPULSwfdQvLR93C8lG3sHzULSwntctS8p1aAAAAAAAADM8ntQAAAAAAABieUGuJVdXlVXVnVd1VVdcsejzAI6rqfVV1T1V9ZlXbU6rqo1X179PvJ0/tVVW/P9Xyv1XV8xY3ctifqurpVfXxqrqjqm6rqjdO7eoWBlVVj6+qT1TVv051+1tT+/lVdfNUtx+oqjOn9rOm5bum689b5PhhP6uqA1V1a1X9zbSsbmFwVfX5qvp0VX2qqo5PbebKMLCqOlxVN1TVZ6fXus9Xt+wFQq0lVVUHkrwjyU8neU6Sn6+q5yx2VMAqf5Tk8jVt1yT5WHdfkORj03Iyq+MLpp+rk7xzl8YIPOKhJL/S3c9OcmmS10/HVXUL4/pmkpd090VJLk5yeVVdmuRtSd4+1e19SV439X9dkvu6+5lJ3j71AxbjjUnuWLWsbmE5vLi7L+7ulWnZXBnG9ntJPtLdz0pyUWbHXnXL0hNqLa8fS3JXd3+uu7+V5C+SvGLBYwIm3f0PSe5d0/yKJO+fLr8/yRWr2v+4Z/45yeGq+sHdGSmQJN395e7+l+ny/2Q22T8adQvDmurvf6fFg9NPJ3lJkhum9rV1e7Keb0jy0qqqXRouMKmqc5L8bJL3TMsVdQvLylwZBlVV35fkhUnemyTd/a3uvj/qlj1AqLW8jib54qrlE1MbMK4f6O4vJ7M30JN8/9SunmEg06mNLklyc9QtDG06hdmnktyT5KNJ/iPJ/d390NRldW1+p26n67+e5OzdHTGQ5HeT/FqSb0/LZ0fdwjLoJH9bVbdU1dVTm7kyjOsZSb6W5A+nU/6+p6qeEHXLHiDUWl7r/Xda7/oogO2gnmEQVfXEJH+V5Je6+7836rpOm7qFXdbdD3f3xUnOyexMBs9er9v0W93CglXVy5Lc0923rG5ep6u6hfG8oLufl9kpyl5fVS/coK/ahcU7I8nzkryzuy9J8n955FSD61G3LA2h1vI6keTpq5bPSXL3gsYCzOerJz+6Pf2+Z2pXzzCAqjqYWaD1p939walZ3cISmE6l8veZfSfe4ao6Y7pqdW1+p26n65+U7z5VMLCzXpDk5VX1+cxOof+SzD65pW5hcN199/T7niQfyuyfScyVYVwnkpzo7pun5RsyC7nULUtPqLW8Ppnkgqo6v6rOTHJVkmMLHhOwsWNJXjNdfk2Sv17V/os1c2mSr5/8KDiwO6bv53hvkju6+3dWXaVuYVBVdaSqDk+XDyX5icy+D+/jSa6cuq2t25P1fGWSm7rbf5/CLurua7v7nO4+L7PXsDd19y9E3cLQquoJVfW9Jy8n+akkn4m5Mgyru7+S5ItVdeHU9NIkt0fdsgeU+eDyqqqfyey/2g4keV93v2XBQwImVfXnSV6U5KlJvprkN5J8OMn1Sc5N8oUkr+rue6c30/8gyeVJvpHktd19fBHjhv2qqn48yT8m+XQe+Y6PX8/se7XULQyoqn40sy+3PpDZP+td391vrqpnZPYJkKckuTXJq7v7m1X1+CR/ktl35t2b5Kru/txiRg9U1YuS/Gp3v0zdwtimGv3QtHhGkj/r7rdU1dkxV4ZhVdXFSd6T5Mwkn0vy2kzz5qhblphQCwAAAAAAgOE5/SAAAAAAAADDE2oBAAAAAAAwPKEWAAAAAAAAwxNqAQAAAAAAMDyhFgAAAAAAAMMTagEAAAAAADA8oRYAAAAAAADDE2oBAAAAAAAwvP8Hc1NwM/BmfSsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 2160x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.scatter(list(range(len(y_pred_with_zeros_lr))), y_pred_with_zeros_lr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video has been successfully created!\n"
     ]
    }
   ],
   "source": [
    "make_video(y_pred_with_zeros_lr, 'LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обробка відео із NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175 : 1175.jpg hasn't got any features!\n",
      "176 : 1176.jpg hasn't got any features!\n",
      "177 : 1177.jpg hasn't got any features!\n",
      "178 : 1178.jpg hasn't got any features!\n",
      "183 : 1183.jpg hasn't got any features!\n",
      "184 : 1184.jpg hasn't got any features!\n",
      "185 : 1185.jpg hasn't got any features!\n",
      "186 : 1186.jpg hasn't got any features!\n",
      "187 : 1187.jpg hasn't got any features!\n",
      "188 : 1188.jpg hasn't got any features!\n",
      "189 : 1189.jpg hasn't got any features!\n",
      "190 : 1190.jpg hasn't got any features!\n",
      "191 : 1191.jpg hasn't got any features!\n",
      "192 : 1192.jpg hasn't got any features!\n",
      "193 : 1193.jpg hasn't got any features!\n",
      "194 : 1194.jpg hasn't got any features!\n",
      "195 : 1195.jpg hasn't got any features!\n",
      "196 : 1196.jpg hasn't got any features!\n",
      "197 : 1197.jpg hasn't got any features!\n",
      "198 : 1198.jpg hasn't got any features!\n",
      "199 : 1199.jpg hasn't got any features!\n",
      "254 : 1254.jpg hasn't got any features!\n",
      "255 : 1255.jpg hasn't got any features!\n",
      "256 : 1256.jpg hasn't got any features!\n",
      "257 : 1257.jpg hasn't got any features!\n",
      "258 : 1258.jpg hasn't got any features!\n",
      "259 : 1259.jpg hasn't got any features!\n",
      "260 : 1260.jpg hasn't got any features!\n",
      "261 : 1261.jpg hasn't got any features!\n",
      "262 : 1262.jpg hasn't got any features!\n",
      "263 : 1263.jpg hasn't got any features!\n",
      "264 : 1264.jpg hasn't got any features!\n",
      "265 : 1265.jpg hasn't got any features!\n",
      "266 : 1266.jpg hasn't got any features!\n",
      "267 : 1267.jpg hasn't got any features!\n",
      "268 : 1268.jpg hasn't got any features!\n",
      "269 : 1269.jpg hasn't got any features!\n",
      "270 : 1270.jpg hasn't got any features!\n",
      "271 : 1271.jpg hasn't got any features!\n",
      "272 : 1272.jpg hasn't got any features!\n",
      "273 : 1273.jpg hasn't got any features!\n",
      "274 : 1274.jpg hasn't got any features!\n",
      "275 : 1275.jpg hasn't got any features!\n",
      "276 : 1276.jpg hasn't got any features!\n",
      "277 : 1277.jpg hasn't got any features!\n",
      "278 : 1278.jpg hasn't got any features!\n",
      "279 : 1279.jpg hasn't got any features!\n",
      "280 : 1280.jpg hasn't got any features!\n",
      "580 : 1580.jpg hasn't got any features!\n",
      "608 : 1608.jpg hasn't got any features!\n",
      "609 : 1609.jpg hasn't got any features!\n",
      "\n",
      "X_test_video shape: (589, 32)\n"
     ]
    }
   ],
   "source": [
    "X_test_video, ids_nn, ids_for_zero_nn = create_X_for_nn(500, \"video_frames\")\n",
    "\n",
    "print()\n",
    "print(\"X_test_video shape:\", X_test_video.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241.jpg hasn't got any features!\n",
      "267.jpg hasn't got any features!\n",
      "269.jpg hasn't got any features!\n",
      "39.jpg hasn't got any features!\n",
      "46.jpg hasn't got any features!\n",
      "91.jpg hasn't got any features!\n",
      "92.jpg hasn't got any features!\n",
      "93.jpg hasn't got any features!\n",
      "\n",
      "X_for_nn shape: (261, 32)\n",
      "y_for_nn shape: (261,)\n"
     ]
    }
   ],
   "source": [
    "X_for_nn, y_for_nn = create_X_and_y_pca(500, directory_test)\n",
    "\n",
    "print()\n",
    "print(\"X_for_nn shape:\", X_for_nn.shape)\n",
    "print(\"y_for_nn shape:\", y_for_nn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(300,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier(hidden_layer_sizes=(300,))\n",
    "\n",
    "nn.fit(X_for_nn, y_for_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nn = nn.predict(X_test_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 2,\n",
       "       2, 0, 2, 2, 1, 1, 1, 2, 1, 2, 0, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2,\n",
       "       2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 0,\n",
       "       0, 0, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 2, 1, 0, 2, 2,\n",
       "       2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 1,\n",
       "       1, 2, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 1, 2, 0, 2, 2, 0, 2, 2, 2, 1, 0, 2, 0, 2, 0, 2, 0, 2, 1, 2,\n",
       "       2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 0, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 0, 2, 0,\n",
       "       2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 2, 0, 2, 0, 1, 2, 1, 2,\n",
       "       2, 2, 2, 1, 2, 1, 1, 0, 1, 1, 1, 2, 0, 1, 1, 2, 1, 2, 2, 2, 2, 0,\n",
       "       2, 0, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0,\n",
       "       0, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "       0, 0, 1, 1, 1, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 1, 2,\n",
       "       0, 0, 2, 0, 2, 1, 1, 2, 1, 2, 2, 0, 2, 0, 1, 2, 2, 1, 0, 1, 0, 0,\n",
       "       1, 2, 0, 2, 0, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_with_zeros_nn = add_zeros(y_pred_nn, ids_nn, ids_for_zero_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 2,\n",
       "       2, 0, 2, 2, 1, 1, 1, 2, 1, 2, 0, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2,\n",
       "       2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 0,\n",
       "       0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 2,\n",
       "       1, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2,\n",
       "       2, 2, 1, 1, 1, 2, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2, 0, 2, 2, 2, 1, 0, 2, 0, 2, 0, 2,\n",
       "       0, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 0, 2, 2, 2, 1, 1, 2, 2,\n",
       "       2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2,\n",
       "       2, 0, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 2, 0, 2, 0,\n",
       "       1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 0, 1, 1, 1, 2, 0, 1, 1, 2, 1, 2,\n",
       "       2, 2, 2, 0, 2, 0, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 0, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2,\n",
       "       2, 2, 2, 1, 0, 0, 1, 1, 1, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2, 0,\n",
       "       2, 2, 1, 2, 0, 0, 2, 0, 0, 2, 1, 1, 2, 1, 2, 2, 0, 2, 0, 1, 2, 2,\n",
       "       1, 0, 1, 0, 0, 1, 2, 0, 2, 0, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_with_zeros_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.scatter(list(range(len(y_pred_with_zeros_nn))), y_pred_with_zeros_nn);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video has been successfully created!\n"
     ]
    }
   ],
   "source": [
    "make_video(y_pred_with_zeros_nn, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Відео з візуалізацією процесу розпізнавання"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"main_photo.jpg\", cv2.IMREAD_GRAYSCALE)  # queryiamge\n",
    "img = cv2.resize(img, (480, 480))\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Features\n",
    "orb = cv2.ORB_create(1500)\n",
    "kp_image, desc_image = orb.detectAndCompute(img, None)\n",
    "\n",
    "# Feature matching\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "# For video recording\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "# video_name = 'video_detection.avi'\n",
    "# resolution = (1120, 480)\n",
    "# out = cv2.VideoWriter(video_name, fourcc, 20.0, resolution, isColor=False)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # trainimage\n",
    "    kp_grayframe, desc_grayframe = orb.detectAndCompute(grayframe, None)\n",
    "    \n",
    "    matches = bf.match(desc_image, desc_grayframe)\n",
    "    matches = sorted(matches, key = lambda x: x.distance)\n",
    "\n",
    "    query_pts = np.float32([kp_image[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    train_pts = np.float32([kp_grayframe[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    _, mask = cv2.findHomography(query_pts, train_pts, cv2.RANSAC, 5.0)\n",
    "    matches_mask = mask.ravel().tolist()\n",
    "    \n",
    "    true_matches = []\n",
    "    for index, el in enumerate(matches_mask):\n",
    "        if el == 1:\n",
    "            true_matches.append(matches[index])\n",
    "    \n",
    "    matching_true_relults = cv2.drawMatches(img, kp_image, grayframe, kp_grayframe, true_matches, None)\n",
    "\n",
    "    # out.write(matching_true_relults)\n",
    "    \n",
    "    cv2.imshow(\"True Matches\", matching_true_relults)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "# out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не знаю, чи вдалося реалізувати те, що потрібно було, проте мені було досить цікаво написати такий код. У майбутньому його можна якось докрутити, щоб програма прорисовувала контури машинки на відео. Проте чомусь я не зміг записати відео через код у Пайтоні, дійсно дуже довго розбирався, але так і не вийшло, тому я записав роботу програми через запис екрану на Windows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
